{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a930c50-7a94-4f98-a076-3ec191c68f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV saved to Flt-times-updated.586473.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from geopy import distance\n",
    "import math as ma\n",
    "from itertools import islice\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def parse_sensor_info(sensor_info: str):\n",
    "    \"\"\"\n",
    "    Parses the Sensor Info column to extract structured data for sensors.\n",
    "\n",
    "    Parameters:\n",
    "        sensor_info (str): The Sensor Info string.\n",
    "\n",
    "    Returns:\n",
    "        defaultdict: A nested defaultdict with structured data for each sensor type.\n",
    "    \"\"\"\n",
    "    # Ensure sensor_info is a string\n",
    "    if sensor_info is None or pd.isnull(sensor_info):\n",
    "        sensor_info = \"\"\n",
    "    else:\n",
    "        sensor_info = str(sensor_info)\n",
    "        \n",
    "    parsed_data = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "\n",
    "    # Regex for engine run details (unchanged)\n",
    "    engine_run_pattern = re.compile(\n",
    "        r\"(?P<sensor>[A-Za-z0-9]+)\\s+monitor\\s+reports\\s+Engine\\s+Run\\s+(?P<duration>\\d+)\\s+minutes,\\s+\"\n",
    "        r\"starts\\s+at\\s+T=(?P<start_time>\\d+)\\s+and:\\s+(?P<msl>\\d+)\\s+msl\\s+\\[(?P<agl>-?\\d+)\\s+agl\\];\\s+\"\n",
    "        r\"Height\\s+gain/loss\\s+is:\\s+(?P<hgl>-?\\d+)\"\n",
    "    )\n",
    "\n",
    "    # Regex for noise registration details (unchanged)\n",
    "    noise_registration_pattern = re.compile(\n",
    "        r\"Motor\\s+noise\\s+registered\\s+by\\s+(?P<sensor>[A-Za-z0-9]+)\\s+sensor\\s+at\\s+t=\\[\\s*(?P<times>[^\\]]+)\\s*\\]\"\n",
    "        r\"\\s+and\\s+\\[\\s*(?P<agl>[^\\]]+)\\s*\\]AGL\"\n",
    "    )\n",
    "\n",
    "    # Parse Engine Run Events\n",
    "    for match in engine_run_pattern.finditer(sensor_info):\n",
    "        sensor = match.group(\"sensor\")\n",
    "        duration = match.group(\"duration\")\n",
    "        start_time = match.group(\"start_time\")\n",
    "        msl = match.group(\"msl\")\n",
    "        agl = match.group(\"agl\")\n",
    "        hgl = match.group(\"hgl\")\n",
    "\n",
    "        parsed_data[sensor][\"Engine_Run\"][\"Duration_Minutes\"].append(int(duration))\n",
    "        parsed_data[sensor][\"Engine_Run\"][\"Start_Times\"].append(int(start_time))\n",
    "        parsed_data[sensor][\"Engine_Run\"][\"Altitudes_MSL\"].append(int(msl))\n",
    "        parsed_data[sensor][\"Engine_Run\"][\"Altitudes_AGL\"].append(float(agl))\n",
    "        parsed_data[sensor][\"Engine_Run\"][\"Height_Gain_Loss\"].append(int(hgl))\n",
    "\n",
    "    # Parse Noise Registration Events\n",
    "    for match in noise_registration_pattern.finditer(sensor_info):\n",
    "        sensor = match.group(\"sensor\")\n",
    "        times_str = match.group(\"times\")\n",
    "        agl_str = match.group(\"agl\")\n",
    "\n",
    "        # Extract numbers without requiring quotes\n",
    "        times = re.findall(r\"(\\d+)\", times_str)\n",
    "        times_int = [int(t) for t in times]\n",
    "        parsed_data[sensor][\"Noise_Registration\"][\"Times\"].extend(times_int)\n",
    "\n",
    "        # Split the AGL values and convert to floats\n",
    "        agl_values = [float(a.strip()) for a in agl_str.split(\",\")]\n",
    "        parsed_data[sensor][\"Noise_Registration\"][\"Altitudes_AGL\"].extend(agl_values)\n",
    "\n",
    "    return parsed_data\n",
    "\n",
    "def tokens_match_format(s):\n",
    "    \"\"\"\n",
    "    Returns True if 's' is empty or all comma-separated tokens in 's'\n",
    "    match the 6-digit HHMMSS format. Otherwise False.\n",
    "    \"\"\"\n",
    "    if not s or s.strip() == \"\":\n",
    "        return True\n",
    "    tokens = [token.strip() for token in s.split(\",\") if token.strip()]\n",
    "    for token in tokens:\n",
    "        # Must be exactly 6 digits\n",
    "        if not re.fullmatch(r\"\\d{6}\", token):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def main():\n",
    "    # Define the input CSV, output CSV\n",
    "    # You can update the input_csv to match your actual filename\n",
    "    input_csv = \"Flt-times.805143.csv\"\n",
    "    updated_csv = f\"Flt-times-updated.{os.getpid()}.csv\"\n",
    "    \n",
    "    # Define sensors to extract data for\n",
    "    sensor_types = [\"ENL\", \"MOP\", \"RPM\"]\n",
    "\n",
    "    with open(input_csv, \"r\", newline=\"\", encoding=\"utf-8\") as infile, \\\n",
    "         open(updated_csv, \"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "        \n",
    "        reader = csv.DictReader(infile)\n",
    "        \n",
    "        # Define additional columns for sensor-specific data\n",
    "        sensor_columns = (\n",
    "            [f\"{sensor}_Engine_Run_Start_Times\" for sensor in sensor_types] +\n",
    "            [f\"{sensor}_Engine_Run_Altitudes_MSL\" for sensor in sensor_types] +\n",
    "            [f\"{sensor}_Engine_Run_Altitudes_AGL\" for sensor in sensor_types] +\n",
    "            [f\"{sensor}_Noise_Registration_Times\" for sensor in sensor_types] +\n",
    "            [f\"{sensor}_Noise_Registration_Altitudes_AGL\" for sensor in sensor_types]\n",
    "        )\n",
    "        \n",
    "        # Concatenate with the original fieldnames\n",
    "        fieldnames = reader.fieldnames + sensor_columns\n",
    "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "        \n",
    "        # Write the header\n",
    "        writer.writeheader()\n",
    "        \n",
    "        # Process each row\n",
    "        for row in reader:\n",
    "            sensor_info = row.get(\"Sensor Info\", \"\")\n",
    "            structured_data = parse_sensor_info(sensor_info)\n",
    "            \n",
    "            # Add parsed sensor data to the row for each sensor type\n",
    "            for sensor in sensor_types:\n",
    "                engine_run = structured_data.get(sensor, {}).get(\"Engine_Run\", {})\n",
    "                noise_reg = structured_data.get(sensor, {}).get(\"Noise_Registration\", {})\n",
    "\n",
    "                # For MOP and RPM, remove decimals by converting the times to integers.\n",
    "                if sensor in [\"MOP\", \"RPM\"]:\n",
    "                    times_str = \",\".join(str(int(x)) for x in engine_run.get(\"Start_Times\", []))\n",
    "                else:\n",
    "                    times_str = \",\".join(map(str, engine_run.get(\"Start_Times\", [])))\n",
    "                \n",
    "                row[f\"{sensor}_Engine_Run_Start_Times\"] = times_str\n",
    "                row[f\"{sensor}_Engine_Run_Altitudes_MSL\"] = \",\".join(map(str, engine_run.get(\"Altitudes_MSL\", [])))\n",
    "                row[f\"{sensor}_Engine_Run_Altitudes_AGL\"] = \",\".join(map(str, engine_run.get(\"Altitudes_AGL\", [])))\n",
    "                row[f\"{sensor}_Noise_Registration_Times\"] = \",\".join(map(str, noise_reg.get(\"Times\", [])))\n",
    "                row[f\"{sensor}_Noise_Registration_Altitudes_AGL\"] = \",\".join(map(str, noise_reg.get(\"Altitudes_AGL\", [])))\n",
    "            \n",
    "            # At this point, we have updated row with the new columns.\n",
    "            # We must check if each of the 3 *Engine_Run_Start_Times columns* is in valid HHMMSS format.\n",
    "            # If any fails, skip (don't write).\n",
    "            all_valid = True\n",
    "            for sensor in sensor_types:\n",
    "                col_name = f\"{sensor}_Engine_Run_Start_Times\"\n",
    "                val = row.get(col_name, \"\")\n",
    "                if not tokens_match_format(val):\n",
    "                    all_valid = False\n",
    "                    break\n",
    "            \n",
    "            if not all_valid:\n",
    "                # Skip this row entirely\n",
    "                continue\n",
    "\n",
    "            # If we reach here, the row is valid. Write it.\n",
    "            writer.writerow(row)\n",
    "    \n",
    "    print(f\"Updated CSV saved to {updated_csv}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b93140-2764-45c8-aed6-119527f9dd6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gdal_test)",
   "language": "python",
   "name": "gdal_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
